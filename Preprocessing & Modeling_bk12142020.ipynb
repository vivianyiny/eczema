{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#!pip install xgboost\n",
    "#!pip install ftfy\n",
    "#!pip install plotly"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>.container { width:95% !important; }</style>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Standard Imports\n",
    "import nltk\n",
    "import pandas                        as pd\n",
    "import numpy                         as np\n",
    "import seaborn                       as sns\n",
    "import matplotlib.pyplot             as plt\n",
    "import re\n",
    "import ftfy\n",
    "from IPython.display                 import display_html\n",
    "from IPython.core.display            import display, HTML\n",
    "\n",
    "# Proprocessing, Modeling, & Evaluation\n",
    "from nltk.corpus                     import stopwords\n",
    "from nltk.stem                       import WordNetLemmatizer\n",
    "from nltk.tokenize                   import RegexpTokenizer \n",
    "from sklearn.ensemble                import RandomForestClassifier\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer, CountVectorizer\n",
    "from sklearn.linear_model            import LogisticRegression\n",
    "from sklearn.model_selection         import GridSearchCV, train_test_split, cross_val_score\n",
    "from sklearn.metrics                 import accuracy_score, recall_score, roc_auc_score, matthews_corrcoef\n",
    "from sklearn.pipeline                import Pipeline\n",
    "from sklearn.svm                     import SVC\n",
    "from sklearn.tree                    import DecisionTreeClassifier\n",
    "from xgboost                         import XGBClassifier\n",
    "\n",
    "# Custom Modules\n",
    "import graphs\n",
    "import metrics\n",
    "\n",
    "\n",
    "# Notebook settings & styles\n",
    "sns.set(style = \"white\", palette = \"deep\")\n",
    "display(HTML(\"<style>.container { width:95% !important; }</style>\"))\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "Annotated_Sample = pd.read_csv('./Reddit Data/All/Reddit Eczema_All_20201201_Sample_Annotated.csv', encoding = \"iso-8859-1\" )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Annotated_Sample[\"body\"] =  Annotated_Sample[\"body\"].apply(lambda x: re.sub(r'[^a-z]',' ', str(x)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Annotated_Sample [\"body\"] = Annotated_Sample [\"body\"].map(ftfy.fix_encoding)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\Ying.Ying_Zenbook\\AppData\\Roaming\\nltk_data..\n",
      "[nltk_data]     .\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     C:\\Users\\Ying.Ying_Zenbook\\AppData\\Roaming\\nltk_data..\n",
      "[nltk_data]     .\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "# Downloading the default stopwords\n",
    "\n",
    "nltk.download(\"stopwords\");\n",
    "\n",
    "# Adding our stopwords to the English set\n",
    "\n",
    "#new_stopwords = [\"like\", \"just\", \"make\", \"cook\",\"use\", \"chicken\", \"recipe\", \"sauce\"]\n",
    "\n",
    "stopwords     = stopwords.words('english')\n",
    "\n",
    "#stopwords.extend(new_stopwords)\n",
    "\n",
    "# Instantiating the lemmatizier and tokenizer\n",
    "# The tokenizer will only keep text\n",
    "nltk.download('wordnet')\n",
    "lemmatizer = WordNetLemmatizer()\n",
    "tokenizer  = RegexpTokenizer(r'\\w+')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cleaning_data(dataframe):\n",
    "   \n",
    "    dataframe[\"body\"] =  dataframe[\"body\"].apply(lambda x: re.sub(r'[^a-z]',' ',str(x)))\n",
    "    \n",
    "    dataframe [\"body\"] = dataframe [\"body\"].map(ftfy.fix_encoding)\n",
    "    \n",
    "    if 'Annotation' in dataframe :\n",
    "        dataframe[\"label\"] = dataframe[\"Annotation\"].apply(lambda x: 1 if x == \"R\" else 0)\n",
    "    \n",
    "    #Annotated_Sample.drop(columns=['Annotation'],inplace=True)\n",
    "    dataframe.rename(columns={'Author':'author'},inplace=True)\n",
    "    \n",
    "    # Setting up the lemmatizer\n",
    "\n",
    "    lemmatized_posts = []\n",
    "\n",
    "    for post in dataframe[\"body\"]:\n",
    "        tokens = tokenizer.tokenize(post)\n",
    "        post   = [lemmatizer.lemmatize(post) for post in tokens]\n",
    "        lemmatized_posts.append(\" \".join(post))\n",
    "\n",
    "    # Appending the lemmatized posts to the dataframe\n",
    "\n",
    "    dataframe[\"lemmatized_text\"] = lemmatized_posts\n",
    "\n",
    "    #remove URL\n",
    "    dataframe[\"lemmatized_text\"] = dataframe[\"lemmatized_text\"].str.replace(\"http\\S+\", \"\")\n",
    "    \n",
    "    #lower case\n",
    "    dataframe[\"lemmatized_text\"] = dataframe[\"lemmatized_text\"].str.lower()\n",
    "    \n",
    "     #remove none letters\n",
    "   \n",
    "\n",
    "\n",
    "    # Checking the head of the dataframe\n",
    "    #dataframe.head()\n",
    "\n",
    "    return dataframe\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>author</th>\n",
       "      <th>body</th>\n",
       "      <th>Annotation</th>\n",
       "      <th>label</th>\n",
       "      <th>lemmatized_text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Hanniballbearings</td>\n",
       "      <td>t s just one of those things    hate that it ...</td>\n",
       "      <td>R</td>\n",
       "      <td>1</td>\n",
       "      <td>t s just one of those thing hate that it doe t...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>cleverleper</td>\n",
       "      <td>feel you   ve thought the same during awful ...</td>\n",
       "      <td>I</td>\n",
       "      <td>0</td>\n",
       "      <td>feel you ve thought the same during awful flar...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>sd_red_lobster</td>\n",
       "      <td>you can also try asking on  r ecze   s there h...</td>\n",
       "      <td>R</td>\n",
       "      <td>1</td>\n",
       "      <td>you can also try asking on r ecze s there have...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Rumanaaa</td>\n",
       "      <td>ve never heard of this   hank you for your i...</td>\n",
       "      <td>I</td>\n",
       "      <td>0</td>\n",
       "      <td>ve never heard of this hank you for your input...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>touchyfeelies</td>\n",
       "      <td>hanks</td>\n",
       "      <td>I</td>\n",
       "      <td>0</td>\n",
       "      <td>hank</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              author                                               body  \\\n",
       "0  Hanniballbearings   t s just one of those things    hate that it ...   \n",
       "1        cleverleper    feel you   ve thought the same during awful ...   \n",
       "2     sd_red_lobster  you can also try asking on  r ecze   s there h...   \n",
       "3           Rumanaaa    ve never heard of this   hank you for your i...   \n",
       "4      touchyfeelies                                             hanks    \n",
       "\n",
       "  Annotation  label                                    lemmatized_text  \n",
       "0          R      1  t s just one of those thing hate that it doe t...  \n",
       "1          I      0  feel you ve thought the same during awful flar...  \n",
       "2          R      1  you can also try asking on r ecze s there have...  \n",
       "3          I      0  ve never heard of this hank you for your input...  \n",
       "4          I      0                                               hank  "
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Annotated_Sample = cleaning_data(Annotated_Sample)\n",
    "Annotated_Sample.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\n# Generating a list of text lengths\\n\\nlengths = [len(text) for text in Annotated_Sample[\"body\"]]\\n\\n# Plotting the text lengths\\n\\nplt.figure(figsize = (16,6), facecolor = \"white\")\\nsns.distplot(lengths, kde = False, bins = 100, color = \"black\")\\nplt.axvline(np.mean(lengths), color = \"red\")\\nplt.title(\"Distribution Of Text Length\", size = 18)\\nplt.xlabel(\"Words\", size = 16)\\nplt.ylabel(\"Frequency\", size = 16)\\nplt.xticks(np.arange(0,23500,1500), size = 14)\\nplt.yticks(size = 14);\\n\\n# The red line marks the mean length\\n'"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"\n",
    "# Generating a list of text lengths\n",
    "\n",
    "lengths = [len(text) for text in Annotated_Sample[\"body\"]]\n",
    "\n",
    "# Plotting the text lengths\n",
    "\n",
    "plt.figure(figsize = (16,6), facecolor = \"white\")\n",
    "sns.distplot(lengths, kde = False, bins = 100, color = \"black\")\n",
    "plt.axvline(np.mean(lengths), color = \"red\")\n",
    "plt.title(\"Distribution Of Text Length\", size = 18)\n",
    "plt.xlabel(\"Words\", size = 16)\n",
    "plt.ylabel(\"Frequency\", size = 16)\n",
    "plt.xticks(np.arange(0,23500,1500), size = 14)\n",
    "plt.yticks(size = 14);\n",
    "\n",
    "# The red line marks the mean length\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\n# Saving the vectorized dfs to a new dataframe\\nvec = CountVectorizer(stop_words = \"english\")\\n\\n# Fit-transforming the vectorizer\\nvec_sample     = vec.fit_transform(Annotated_Sample[\"body\"])\\n\\nsample_vectorized     = pd.DataFrame(vec_sample.toarray(), columns = vec.get_feature_names())\\nsample_vectorized.sum().sort_values(ascending=False)\\n\\n'"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"\n",
    "# Saving the vectorized dfs to a new dataframe\n",
    "vec = CountVectorizer(stop_words = \"english\")\n",
    "\n",
    "# Fit-transforming the vectorizer\n",
    "vec_sample     = vec.fit_transform(Annotated_Sample[\"body\"])\n",
    "\n",
    "sample_vectorized     = pd.DataFrame(vec_sample.toarray(), columns = vec.get_feature_names())\n",
    "sample_vectorized.sum().sort_values(ascending=False)\n",
    "\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### CountVectorizer\n",
    "\n",
    "Convert a collection of text documents to a matrix of token counts\n",
    "\n",
    "<https://scikit-learn.org/stable/modules/generated/sklearn.feature_extraction.text.CountVectorizer.html>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "eczema           475\n",
       "skin             376\n",
       "wa               355\n",
       "like             284\n",
       "get              256\n",
       "                ... \n",
       "peace since        1\n",
       "peace skin         1\n",
       "peak               1\n",
       "peak summer        1\n",
       "literally day      1\n",
       "Length: 32432, dtype: int64"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vec_lem = CountVectorizer(ngram_range =(1,2),stop_words = stopwords)\n",
    "\n",
    "vec_sample_lem     = vec_lem.fit_transform(Annotated_Sample[\"lemmatized_text\"])\n",
    "\n",
    "sample_vectorized_lem     = pd.DataFrame(vec_sample_lem.toarray(), columns = vec_lem.get_feature_names())\n",
    "\n",
    "sample_vectorized_lem.sum().sort_values(ascending=False)\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### TfidfVectorizer\n",
    "\n",
    "TF-IDF (term frequency-inverse document frequency) was invented for document search and information retrieval. It works by increasing proportionally to the number of times a word appears in a document, but is offset by the number of documents that contain the word. \n",
    "\n",
    "\n",
    "<https://scikit-learn.org/stable/modules/generated/sklearn.feature_extraction.text.TfidfVectorizer.html>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "fault             0.183883\n",
       "hile fun          0.183883\n",
       "high hile         0.183883\n",
       "nothing person    0.183883\n",
       "conscious know    0.183883\n",
       "                    ...   \n",
       "preying people    0.000000\n",
       "price             0.000000\n",
       "price aybe        0.000000\n",
       "price better      0.000000\n",
       "aaf               0.000000\n",
       "Name: 0, Length: 32432, dtype: float64"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tvec_lem = TfidfVectorizer(ngram_range =(1,2),stop_words = stopwords)\n",
    "\n",
    "tvec_sample_lem     = tvec_lem.fit_transform(Annotated_Sample[\"lemmatized_text\"])\n",
    "\n",
    "tsample_vectorized_lem     = pd.DataFrame(tvec_sample_lem.toarray(),columns = tvec_lem.get_feature_names())\n",
    "\n",
    "tsample_vectorized_lem.T[0].sort_values(ascending=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Modelling\n",
    "\n",
    "__Create Test and Training data split__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "X = Annotated_Sample[\"lemmatized_text\"]\n",
    "y = Annotated_Sample[\"label\"]\n",
    "\n",
    "# The random state ensures reproducability\n",
    "# The stratify argument preserves the distribution of classes\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X,\n",
    "                                                    y,\n",
    "                                                    random_state = 42,\n",
    "                                                    stratify     = y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## __Logistic Regression__\n",
    "\n",
    "The logistic regression is very similar to the linear regression, but it uses a logit function to bend the line so that it can predict either 0 or 1.\n",
    "\n",
    "The gridsearch will be searching hyperparameters for the vectorizers, not the logistic regression.\n",
    "\n",
    "__Count Vectorizer__\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Setting up the pipeline\n",
    "\n",
    "cvec_lr_pipe = Pipeline([(\"cvec\", CountVectorizer()), \n",
    "                         (\"log_reg\", LogisticRegression())])\n",
    "\n",
    "# Setting the CVEC hyperparameters\n",
    "\n",
    "cvec_pipe_params = {\"cvec__max_features\": [None], \n",
    "                    \"cvec__ngram_range\" : [(1,2)], \n",
    "                    \"cvec__stop_words\"  : [stopwords]}\n",
    "\n",
    "# Instantiating the grid search\n",
    "\n",
    "cvec_lr_gs = GridSearchCV(cvec_lr_pipe, \n",
    "                          param_grid = cvec_pipe_params, \n",
    "                          cv         = 10)\n",
    "\n",
    "# Fitting the model to the training data\n",
    "\n",
    "cvec_lr_gs.fit(X_train, y_train);\n",
    "\n",
    "# The futurewarning can be ignored"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generating training predictions\n",
    "\n",
    "cvec_lr_train_preds = cvec_lr_gs.predict(X_train)\n",
    "\n",
    "# Generating test predictions\n",
    "\n",
    "cvec_lr_preds       = cvec_lr_gs.predict(X_test)\n",
    "\n",
    "# Generating test probabilities\n",
    "\n",
    "cvec_lr_probas      = cvec_lr_gs.predict_proba(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Accuracy</th>\n",
       "      <td>0.998797</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Sensitivity</th>\n",
       "      <td>0.998469</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Specificity</th>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>AUROC</th>\n",
       "      <td>0.999234</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Matthews Corr. Coef.</th>\n",
       "      <td>0.996439</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                         Score\n",
       "Accuracy              0.998797\n",
       "Sensitivity           0.998469\n",
       "Specificity           1.000000\n",
       "AUROC                 0.999234\n",
       "Matthews Corr. Coef.  0.996439"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Training metrics\n",
    "\n",
    "metrics.binary_classification_summary(y_train, cvec_lr_train_preds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Accuracy</th>\n",
       "      <td>0.827338</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Sensitivity</th>\n",
       "      <td>0.890411</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Specificity</th>\n",
       "      <td>0.593220</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>AUROC</th>\n",
       "      <td>0.741816</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Matthews Corr. Coef.</th>\n",
       "      <td>0.483631</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                         Score\n",
       "Accuracy              0.827338\n",
       "Sensitivity           0.890411\n",
       "Specificity           0.593220\n",
       "AUROC                 0.741816\n",
       "Matthews Corr. Coef.  0.483631"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Test metrics\n",
    "\n",
    "metrics.binary_classification_summary(y_test, cvec_lr_preds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Predicted Irrelated</th>\n",
       "      <th>Predicted Related</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Actual Irrelated</th>\n",
       "      <td>35</td>\n",
       "      <td>24</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Actual Related</th>\n",
       "      <td>24</td>\n",
       "      <td>195</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                  Predicted Irrelated  Predicted Related\n",
       "Actual Irrelated                   35                 24\n",
       "Actual Related                     24                195"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Generating a confusion matrix on the test results\n",
    "\n",
    "metrics.confusion_matrix_dataframe(y_test, \n",
    "                                   cvec_lr_preds,\n",
    "                                   columns = [\"Predicted Irrelated\", \"Predicted Related\"],\n",
    "                                   index   = [\"Actual Irrelated\", \"Actual Related\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__TFIDF Vectorization__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Setting up the pipeline\n",
    "\n",
    "tvec_lr_pipe = Pipeline([(\"tvec\", TfidfVectorizer()), \n",
    "                         (\"log_reg\", LogisticRegression())])\n",
    "\n",
    "# Setting TFIDF hyperparameters\n",
    "\n",
    "tvec_pipe_params = {\"tvec__max_features\": [None], \n",
    "                    \"tvec__ngram_range\" : [(1,2)], \n",
    "                    \"tvec__stop_words\"  : [stopwords]}\n",
    "                    \n",
    "# Instantiating the grid search\n",
    "\n",
    "tvec_lr_gs = GridSearchCV(tvec_lr_pipe, \n",
    "                          param_grid = tvec_pipe_params, \n",
    "                          cv         = 10)\n",
    "\n",
    "# Fitting the model to the training data\n",
    "\n",
    "tvec_lr_gs.fit(X_train, y_train);\n",
    "\n",
    "# The warning is a futurewarning and can be ignored"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generating training predictions\n",
    "\n",
    "tvec_lr_train_preds = tvec_lr_gs.predict(X_train)\n",
    "\n",
    "# Generating test predictions\n",
    "\n",
    "tvec_lr_preds       = tvec_lr_gs.predict(X_test) \n",
    "\n",
    "# Generating test probabilities\n",
    "\n",
    "tvec_lr_probas     = tvec_lr_gs.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Accuracy</th>\n",
       "      <td>0.808664</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Sensitivity</th>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Specificity</th>\n",
       "      <td>0.106742</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>AUROC</th>\n",
       "      <td>0.553371</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Matthews Corr. Coef.</th>\n",
       "      <td>0.292985</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                         Score\n",
       "Accuracy              0.808664\n",
       "Sensitivity           1.000000\n",
       "Specificity           0.106742\n",
       "AUROC                 0.553371\n",
       "Matthews Corr. Coef.  0.292985"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "# Training metrics\n",
    "\n",
    "metrics.binary_classification_summary(y_train, tvec_lr_train_preds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Accuracy</th>\n",
       "      <td>0.798561</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Sensitivity</th>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Specificity</th>\n",
       "      <td>0.050847</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>AUROC</th>\n",
       "      <td>0.525424</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Matthews Corr. Coef.</th>\n",
       "      <td>0.201229</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                         Score\n",
       "Accuracy              0.798561\n",
       "Sensitivity           1.000000\n",
       "Specificity           0.050847\n",
       "AUROC                 0.525424\n",
       "Matthews Corr. Coef.  0.201229"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Test metrics\n",
    "\n",
    "metrics.binary_classification_summary(y_test, tvec_lr_preds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Predicted Irrelated</th>\n",
       "      <th>Predicted Related</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Actual Irrelated</th>\n",
       "      <td>3</td>\n",
       "      <td>56</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Actual Related</th>\n",
       "      <td>0</td>\n",
       "      <td>219</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                  Predicted Irrelated  Predicted Related\n",
       "Actual Irrelated                    3                 56\n",
       "Actual Related                      0                219"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Generating a confusion matrix on the test results\n",
    "\n",
    "metrics.confusion_matrix_dataframe(y_test, \n",
    "                                   tvec_lr_preds,\n",
    "                                   columns = [\"Predicted Irrelated\", \"Predicted Related\"],\n",
    "                                   index   = [\"Actual Irrelated\", \"Actual Related\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Support Vector Classifier\n",
    "\n",
    "A support vector machine (in this case a classifier) is at its core a linear model. However, instead of running like a logistic regression, it seeks to linearly separate the data. To do that, it uses a kernel to raise the data into n-dimensional space. It then uses a line, plane (3-dimensional line), or hyperplane (greater than 3-dimensions) to delineate the data\n",
    "\n",
    "__Count Vectorizer__\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Setting up the pipeline\n",
    "\n",
    "cvec_svc_pipe = Pipeline([(\"cvec\", CountVectorizer()), \n",
    "                         (\"svc\", SVC())])\n",
    "\n",
    "# Setting CVEC and pipe hyperparameters\n",
    "\n",
    "cvec_pipe_params = {\"cvec__max_features\": [None], \n",
    "                    \"cvec__ngram_range\" : [(1,2)], \n",
    "                    \"cvec__stop_words\"  : [stopwords],\n",
    "                    \"svc__C\"            : [1.0],\n",
    "                    \"svc__kernel\"       : [\"linear\"],\n",
    "                    \"svc__gamma\"        : [\"auto\"]}\n",
    "                    \n",
    "# Instantiating the grid search\n",
    "\n",
    "cvec_svc_gs = GridSearchCV(cvec_svc_pipe, \n",
    "                           param_grid = cvec_pipe_params, \n",
    "                           cv         = 10)\n",
    "\n",
    "# Fitting the model to the training data\n",
    "\n",
    "cvec_svc_gs.fit(X_train, y_train);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Generating training predictions\n",
    "\n",
    "cvec_svc_train_preds = cvec_svc_gs.predict(X_train)\n",
    "\n",
    "# Generating test predictions\n",
    "\n",
    "cvec_svc_preds       = cvec_svc_gs.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Accuracy</th>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Sensitivity</th>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Specificity</th>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>AUROC</th>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Matthews Corr. Coef.</th>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                      Score\n",
       "Accuracy                1.0\n",
       "Sensitivity             1.0\n",
       "Specificity             1.0\n",
       "AUROC                   1.0\n",
       "Matthews Corr. Coef.    1.0"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Training metrics\n",
    "\n",
    "metrics.binary_classification_summary(y_train, cvec_svc_train_preds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7975388901787788\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Accuracy</th>\n",
       "      <td>0.827338</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Sensitivity</th>\n",
       "      <td>0.849315</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Specificity</th>\n",
       "      <td>0.745763</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>AUROC</th>\n",
       "      <td>0.797539</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Matthews Corr. Coef.</th>\n",
       "      <td>0.543724</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                         Score\n",
       "Accuracy              0.827338\n",
       "Sensitivity           0.849315\n",
       "Specificity           0.745763\n",
       "AUROC                 0.797539\n",
       "Matthews Corr. Coef.  0.543724"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Test metrics\n",
    "print(roc_auc_score(y_test, cvec_svc_preds))\n",
    "\n",
    "metrics.binary_classification_summary(y_test, cvec_svc_preds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Predicted Irrelated</th>\n",
       "      <th>Predicted Related</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Actual Irrelated</th>\n",
       "      <td>44</td>\n",
       "      <td>15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Actual Related</th>\n",
       "      <td>33</td>\n",
       "      <td>186</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                  Predicted Irrelated  Predicted Related\n",
       "Actual Irrelated                   44                 15\n",
       "Actual Related                     33                186"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Generating a confusion matrix on the test results\n",
    "\n",
    "metrics.confusion_matrix_dataframe(y_test, \n",
    "                                   cvec_svc_preds,\n",
    "                                   columns = [\"Predicted Irrelated\", \"Predicted Related\"],\n",
    "                                   index   = [\"Actual Irrelated\", \"Actual Related\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**TFIDF Vectorizer**\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Setting up the pipeline\n",
    "\n",
    "tvec_svc_pipe = Pipeline([(\"tvec\", TfidfVectorizer()), \n",
    "                         (\"svc\", SVC())])\n",
    "\n",
    "# Setting TFIDF and pipe hyperparameters\n",
    "\n",
    "tvec_pipe_params = {\"tvec__max_features\": [None], \n",
    "                    \"tvec__ngram_range\" : [(1,2)], \n",
    "                    \"tvec__stop_words\"  : [stopwords],\n",
    "                    \"svc__C\"            : [1.0],\n",
    "                    \"svc__kernel\"       : [\"linear\"],\n",
    "                    \"svc__gamma\"        : [\"auto\"]}\n",
    "                    \n",
    "# Instantiating the grid search\n",
    "\n",
    "tvec_svc_gs = GridSearchCV(tvec_svc_pipe, \n",
    "                           param_grid = tvec_pipe_params, \n",
    "                           cv         = 10)\n",
    "\n",
    "# Fitting the model to the training data\n",
    "\n",
    "tvec_svc_gs.fit(X_train, y_train);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generating training predictions\n",
    "\n",
    "tvec_svc_train_preds = tvec_svc_gs.predict(X_train)\n",
    "\n",
    "# Generating test predictions\n",
    "\n",
    "tvec_svc_preds       = tvec_svc_gs.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Accuracy</th>\n",
       "      <td>0.992780</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Sensitivity</th>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Specificity</th>\n",
       "      <td>0.966292</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>AUROC</th>\n",
       "      <td>0.983146</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Matthews Corr. Coef.</th>\n",
       "      <td>0.978516</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                         Score\n",
       "Accuracy              0.992780\n",
       "Sensitivity           1.000000\n",
       "Specificity           0.966292\n",
       "AUROC                 0.983146\n",
       "Matthews Corr. Coef.  0.978516"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Training metrics\n",
    "\n",
    "metrics.binary_classification_summary(y_train, tvec_svc_train_preds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Accuracy</th>\n",
       "      <td>0.830935</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Sensitivity</th>\n",
       "      <td>0.995434</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Specificity</th>\n",
       "      <td>0.220339</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>AUROC</th>\n",
       "      <td>0.607886</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Matthews Corr. Coef.</th>\n",
       "      <td>0.403440</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                         Score\n",
       "Accuracy              0.830935\n",
       "Sensitivity           0.995434\n",
       "Specificity           0.220339\n",
       "AUROC                 0.607886\n",
       "Matthews Corr. Coef.  0.403440"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Test metrics\n",
    "metrics.binary_classification_summary(y_test, tvec_svc_preds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Predicted Irrelated</th>\n",
       "      <th>Predicted Related</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Actual Irrelated</th>\n",
       "      <td>13</td>\n",
       "      <td>46</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Actual Related</th>\n",
       "      <td>1</td>\n",
       "      <td>218</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                  Predicted Irrelated  Predicted Related\n",
       "Actual Irrelated                   13                 46\n",
       "Actual Related                      1                218"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Generating a confusion matrix on the test results\n",
    "\n",
    "metrics.confusion_matrix_dataframe(y_test, \n",
    "                                   tvec_svc_preds,\n",
    "                                   columns = [\"Predicted Irrelated\", \"Predicted Related\"],\n",
    "                                   index   = [\"Actual Irrelated\", \"Actual Related\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Random Forest Classifier\n",
    "\n",
    "A random forest classifier is a decision tree-based classification method. However, it has advantages over other tree-based models. Firstly, it bootstraps the dataframe to have a random subset of the data, but it also takes a random subset of the features. Having two levels of randomness in the model reduces the likelihood of the model being overfit on training data but it also allows the model to be less prone to variance caused by many features.\n",
    "\n",
    "__Count Vectorizer__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating the pipeline\n",
    "\n",
    "cvec_rf_pipe = Pipeline([(\"cvec\", CountVectorizer()), \n",
    "                         (\"rf\", RandomForestClassifier(random_state = 42))])\n",
    "\n",
    "# Setting CVEC and pipeline hyperparameters\n",
    "\n",
    "cvec_pipe_params = {\"cvec__max_features\"   : [None], \n",
    "                    \"cvec__ngram_range\"    : [(1,2)], \n",
    "                    \"cvec__stop_words\"     : [stopwords],\n",
    "                    \"rf__n_estimators\"     : [72],\n",
    "                    \"rf__min_samples_split\": [6],\n",
    "                    \"rf__min_samples_leaf\" : [2],\n",
    "                    \"rf__max_depth\"        : [20]}\n",
    "\n",
    "# Instantiating the grid search\n",
    "\n",
    "cvec_rf_gs = GridSearchCV(cvec_rf_pipe, \n",
    "                          param_grid = cvec_pipe_params, \n",
    "                          cv         = 10,\n",
    "                          n_jobs     = 6)\n",
    "\n",
    "# Fitting the model to the training data\n",
    "\n",
    "cvec_rf_gs.fit(X_train, y_train);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generating training predictions\n",
    "\n",
    "cvec_rf_train_preds = cvec_rf_gs.predict(X_train)\n",
    "\n",
    "# Generating test predictions\n",
    "\n",
    "cvec_rf_preds       = cvec_rf_gs.predict(X_test) \n",
    "\n",
    "# Generating test probabilities\n",
    "\n",
    "cvec_rf_probas      = cvec_rf_gs.predict_proba(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:846: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  mcc = cov_ytyp / np.sqrt(cov_ytyt * cov_ypyp)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Accuracy</th>\n",
       "      <td>0.7858</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Sensitivity</th>\n",
       "      <td>1.0000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Specificity</th>\n",
       "      <td>0.0000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>AUROC</th>\n",
       "      <td>0.5000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Matthews Corr. Coef.</th>\n",
       "      <td>0.0000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                       Score\n",
       "Accuracy              0.7858\n",
       "Sensitivity           1.0000\n",
       "Specificity           0.0000\n",
       "AUROC                 0.5000\n",
       "Matthews Corr. Coef.  0.0000"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Training metrics\n",
    "\n",
    "metrics.binary_classification_summary(y_train, cvec_rf_train_preds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:846: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  mcc = cov_ytyp / np.sqrt(cov_ytyt * cov_ypyp)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Accuracy</th>\n",
       "      <td>0.78777</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Sensitivity</th>\n",
       "      <td>1.00000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Specificity</th>\n",
       "      <td>0.00000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>AUROC</th>\n",
       "      <td>0.50000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Matthews Corr. Coef.</th>\n",
       "      <td>0.00000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                        Score\n",
       "Accuracy              0.78777\n",
       "Sensitivity           1.00000\n",
       "Specificity           0.00000\n",
       "AUROC                 0.50000\n",
       "Matthews Corr. Coef.  0.00000"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Test metrics\n",
    "\n",
    "metrics.binary_classification_summary(y_test, cvec_rf_preds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Predicted Irrelated</th>\n",
       "      <th>Predicted Related</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Actual Irrelated</th>\n",
       "      <td>0</td>\n",
       "      <td>59</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Actual Related</th>\n",
       "      <td>0</td>\n",
       "      <td>219</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                  Predicted Irrelated  Predicted Related\n",
       "Actual Irrelated                    0                 59\n",
       "Actual Related                      0                219"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Generating a confusion matrix on the test results\n",
    "\n",
    "metrics.confusion_matrix_dataframe(y_test, \n",
    "                                   cvec_rf_preds,\n",
    "                                   columns = [\"Predicted Irrelated\", \"Predicted Related\"],\n",
    "                                   index   = [\"Actual Irrelated\", \"Actual Related\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__TFIDF Vectorizer__\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating the pipeline\n",
    "\n",
    "tvec_rf_pipe = Pipeline([(\"tvec\", TfidfVectorizer()), \n",
    "                         (\"rf\", RandomForestClassifier(random_state = 42))])\n",
    "\n",
    "# Setting the TVEC and pipeline hyperparameters\n",
    "\n",
    "tvec_pipe_params = {\"tvec__max_features\"   : [None], \n",
    "                    \"tvec__ngram_range\"    : [(1,2)], \n",
    "                    \"tvec__stop_words\"     : [stopwords],\n",
    "                    \"rf__n_estimators\"     : [30],\n",
    "                    \"rf__min_samples_split\": [6],\n",
    "                    \"rf__min_samples_leaf\" : [2],\n",
    "                    \"rf__max_depth\"        : [12]}\n",
    "\n",
    "# Instantiating the grid search\n",
    "\n",
    "tvec_rf_gs = GridSearchCV(tvec_rf_pipe, \n",
    "                          param_grid = tvec_pipe_params, \n",
    "                          cv         = 5,\n",
    "                          n_jobs     = 6)\n",
    "\n",
    "# Fitting the model to the testing data\n",
    "\n",
    "tvec_rf_gs.fit(X_train, y_train);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generating training predictions\n",
    "\n",
    "tvec_rf_train_preds = tvec_rf_gs.predict(X_train)\n",
    "\n",
    "# Generating test predictions\n",
    "\n",
    "tvec_rf_preds       = tvec_rf_gs.predict(X_test) \n",
    "\n",
    "# Generating test probabilities\n",
    "\n",
    "tvec_rf_probas      = tvec_rf_gs.predict_proba(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:846: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  mcc = cov_ytyp / np.sqrt(cov_ytyt * cov_ypyp)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Accuracy</th>\n",
       "      <td>0.7858</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Sensitivity</th>\n",
       "      <td>1.0000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Specificity</th>\n",
       "      <td>0.0000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>AUROC</th>\n",
       "      <td>0.5000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Matthews Corr. Coef.</th>\n",
       "      <td>0.0000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                       Score\n",
       "Accuracy              0.7858\n",
       "Sensitivity           1.0000\n",
       "Specificity           0.0000\n",
       "AUROC                 0.5000\n",
       "Matthews Corr. Coef.  0.0000"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Training metrics\n",
    "\n",
    "metrics.binary_classification_summary(y_train, tvec_rf_train_preds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:846: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  mcc = cov_ytyp / np.sqrt(cov_ytyt * cov_ypyp)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Accuracy</th>\n",
       "      <td>0.78777</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Sensitivity</th>\n",
       "      <td>1.00000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Specificity</th>\n",
       "      <td>0.00000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>AUROC</th>\n",
       "      <td>0.50000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Matthews Corr. Coef.</th>\n",
       "      <td>0.00000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                        Score\n",
       "Accuracy              0.78777\n",
       "Sensitivity           1.00000\n",
       "Specificity           0.00000\n",
       "AUROC                 0.50000\n",
       "Matthews Corr. Coef.  0.00000"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Test metrics\n",
    "\n",
    "metrics.binary_classification_summary(y_test, tvec_rf_preds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Predicted Irrelated</th>\n",
       "      <th>Predicted Related</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Actual Irrelated</th>\n",
       "      <td>0</td>\n",
       "      <td>59</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Actual Related</th>\n",
       "      <td>0</td>\n",
       "      <td>219</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                  Predicted Irrelated  Predicted Related\n",
       "Actual Irrelated                    0                 59\n",
       "Actual Related                      0                219"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Generating a confusion matrix on the test results\n",
    "\n",
    "metrics.confusion_matrix_dataframe(y_test, \n",
    "                                   tvec_rf_preds,\n",
    "                                   columns = [\"Predicted Irrelated\", \"Predicted Related\"],\n",
    "                                   index   = [\"Actual Irrelated\", \"Actual Related\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## XGBoost Classifier\n",
    "\n",
    "XGBoost is a tree-based boosting model that iteratively fits tree models on the errors of the previous model and uses gradient descent to help minimize the loss function. Furthermore, the XGBoost is much more computationally efficient and can be parallelized unlike other boosting models.\n",
    "\n",
    "__Count Vectorizer__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[15:48:52] WARNING: C:\\Users\\Administrator\\workspace\\xgboost-win64_release_1.2.0\\src\\learner.cc:516: \n",
      "Parameters: { early_stopping_rounds } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Creating the pipeline\n",
    "# The model's best parameters are shown\n",
    "\n",
    "cvec_xgbc_pipe = Pipeline([(\"cvec\", CountVectorizer()), \n",
    "                           (\"xgbc\", XGBClassifier(n_jobs                = 6,\n",
    "                                                  seed                  = 42,\n",
    "                                                  early_stopping_rounds = 10))])\n",
    "\n",
    "# Setting CVEC and pipeline hyperparameters\n",
    "\n",
    "cvec_pipe_params = {\"cvec__max_features\"   : [None], \n",
    "                    \"cvec__ngram_range\"    : [(1,2)], \n",
    "                    \"cvec__stop_words\"     : [stopwords],\n",
    "                    \"xgbc__max_depth\"      : [3],\n",
    "                    \"xgbc__learning_rate\"  : [0.04],\n",
    "                    \"xgbc__n_estimators\"   : [175],\n",
    "                    \"xgbc__gamma\"          : [3.0]}\n",
    "\n",
    "# Instantiating the grid search\n",
    "\n",
    "cvec_xgbc_gs = GridSearchCV(cvec_xgbc_pipe, \n",
    "                            param_grid = cvec_pipe_params, \n",
    "                            cv         = 5,\n",
    "                            n_jobs     = 6)\n",
    "\n",
    "# Fitting the model to the testing data\n",
    "\n",
    "cvec_xgbc_gs.fit(X_train, y_train);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Generating training predictions\n",
    "\n",
    "cvec_xgbc_train_preds = cvec_xgbc_gs.predict(X_train)\n",
    "\n",
    "# Generating test predictions\n",
    "\n",
    "cvec_xgbc_preds       = cvec_xgbc_gs.predict(X_test) \n",
    "\n",
    "# Generating test probabilities\n",
    "\n",
    "cvec_xgbc_probas      = cvec_xgbc_gs.predict_proba(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Accuracy</th>\n",
       "      <td>0.821901</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Sensitivity</th>\n",
       "      <td>0.998469</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Specificity</th>\n",
       "      <td>0.174157</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>AUROC</th>\n",
       "      <td>0.586313</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Matthews Corr. Coef.</th>\n",
       "      <td>0.368065</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                         Score\n",
       "Accuracy              0.821901\n",
       "Sensitivity           0.998469\n",
       "Specificity           0.174157\n",
       "AUROC                 0.586313\n",
       "Matthews Corr. Coef.  0.368065"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Training metrics\n",
    "\n",
    "metrics.binary_classification_summary(y_train, cvec_xgbc_train_preds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Accuracy</th>\n",
       "      <td>0.823741</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Sensitivity</th>\n",
       "      <td>0.995434</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Specificity</th>\n",
       "      <td>0.186441</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>AUROC</th>\n",
       "      <td>0.590937</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Matthews Corr. Coef.</th>\n",
       "      <td>0.365922</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                         Score\n",
       "Accuracy              0.823741\n",
       "Sensitivity           0.995434\n",
       "Specificity           0.186441\n",
       "AUROC                 0.590937\n",
       "Matthews Corr. Coef.  0.365922"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Test metrics\n",
    "\n",
    "metrics.binary_classification_summary(y_test, cvec_xgbc_preds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Predicted Irrelated</th>\n",
       "      <th>Predicted Related</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Actual Irrelated</th>\n",
       "      <td>11</td>\n",
       "      <td>48</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Actual Related</th>\n",
       "      <td>1</td>\n",
       "      <td>218</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                  Predicted Irrelated  Predicted Related\n",
       "Actual Irrelated                   11                 48\n",
       "Actual Related                      1                218"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Generating a confusion matrix on the test results\n",
    "\n",
    "metrics.confusion_matrix_dataframe(y_test, \n",
    "                                   cvec_xgbc_preds,\n",
    "                                   columns = [\"Predicted Irrelated\", \"Predicted Related\"],\n",
    "                                   index   = [\"Actual Irrelated\", \"Actual Related\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__TFIDF Vectorizer__\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[15:48:59] WARNING: C:\\Users\\Administrator\\workspace\\xgboost-win64_release_1.2.0\\src\\learner.cc:516: \n",
      "Parameters: { early_stopping_rounds } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Creating the pipeline\n",
    "# The model's best parameters are shown\n",
    "\n",
    "tvec_xgbc_pipe = Pipeline([(\"tvec\", TfidfVectorizer()), \n",
    "                           (\"xgbc\", XGBClassifier(n_jobs                = 6,\n",
    "                                                  seed                  = 42,\n",
    "                                                  early_stopping_rounds = 10))])\n",
    "\n",
    "# Setting the TFIDF and pipeline hyperparameters\n",
    "\n",
    "tvec_pipe_params = {\"tvec__max_features\"   : [525], \n",
    "                    \"tvec__ngram_range\"    : [(1,2)], \n",
    "                    \"tvec__stop_words\"     : [stopwords],\n",
    "                    \"xgbc__max_depth\"      : [3],\n",
    "                    \"xgbc__learning_rate\"  : [0.25],\n",
    "                    \"xgbc__n_estimators\"   : [139],\n",
    "                    \"xgbc__gamma\"          : [1.0]}\n",
    "\n",
    "# Instantiating the grid search\n",
    "\n",
    "tvec_xgbc_gs = GridSearchCV(tvec_xgbc_pipe, \n",
    "                            param_grid = tvec_pipe_params, \n",
    "                            cv         = 5,\n",
    "                            n_jobs     = 6)\n",
    "\n",
    "# Fitting the model to the testing data\n",
    "\n",
    "tvec_xgbc_gs.fit(X_train, y_train);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generating training predictions\n",
    "\n",
    "tvec_xgbc_train_preds = tvec_xgbc_gs.predict(X_train)\n",
    "\n",
    "# Generating test predictions\n",
    "\n",
    "tvec_xgbc_preds       = tvec_xgbc_gs.predict(X_test) \n",
    "\n",
    "# Generating test probabilities\n",
    "\n",
    "tvec_xgbc_probas      = tvec_xgbc_gs.predict_proba(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Accuracy</th>\n",
       "      <td>0.959085</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Sensitivity</th>\n",
       "      <td>0.967841</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Specificity</th>\n",
       "      <td>0.926966</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>AUROC</th>\n",
       "      <td>0.947404</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Matthews Corr. Coef.</th>\n",
       "      <td>0.880764</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                         Score\n",
       "Accuracy              0.959085\n",
       "Sensitivity           0.967841\n",
       "Specificity           0.926966\n",
       "AUROC                 0.947404\n",
       "Matthews Corr. Coef.  0.880764"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Training metrics\n",
    "\n",
    "metrics.binary_classification_summary(y_train, tvec_xgbc_train_preds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Accuracy</th>\n",
       "      <td>0.827338</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Sensitivity</th>\n",
       "      <td>0.885845</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Specificity</th>\n",
       "      <td>0.610169</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>AUROC</th>\n",
       "      <td>0.748007</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Matthews Corr. Coef.</th>\n",
       "      <td>0.490058</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                         Score\n",
       "Accuracy              0.827338\n",
       "Sensitivity           0.885845\n",
       "Specificity           0.610169\n",
       "AUROC                 0.748007\n",
       "Matthews Corr. Coef.  0.490058"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Test metrics\n",
    "\n",
    "metrics.binary_classification_summary(y_test, tvec_xgbc_preds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Predicted Irrelated</th>\n",
       "      <th>Predicted Related</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Actual Irrelated</th>\n",
       "      <td>36</td>\n",
       "      <td>23</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Actual Related</th>\n",
       "      <td>25</td>\n",
       "      <td>194</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                  Predicted Irrelated  Predicted Related\n",
       "Actual Irrelated                   36                 23\n",
       "Actual Related                     25                194"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Generating a confusion matrix on the test results\n",
    "\n",
    "metrics.confusion_matrix_dataframe(y_test, \n",
    "                                   tvec_xgbc_preds,\n",
    "                                   columns = [\"Predicted Irrelated\", \"Predicted Related\"],\n",
    "                                   index   = [\"Actual Irrelated\", \"Actual Related\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This function allows for dataframes to be displayed side-by-side\n",
    "\n",
    "def display_side_by_side(*args):\n",
    "    html_str = ''\n",
    "    for df in args:\n",
    "        html_str += df.to_html()\n",
    "    display_html(html_str.replace('table', 'table style=\"display:inline\"'), raw = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:846: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  mcc = cov_ytyp / np.sqrt(cov_ytyt * cov_ypyp)\n"
     ]
    }
   ],
   "source": [
    "# Count vectorizer metrics\n",
    "\n",
    "cvec_accuracy          = [accuracy_score(y_test, cvec_lr_preds), \n",
    "                          accuracy_score(y_test, cvec_svc_preds),\n",
    "                          accuracy_score(y_test, cvec_rf_preds), \n",
    "                          accuracy_score(y_test, cvec_xgbc_preds)]\n",
    "\n",
    "cvec_specificity       = [metrics.specificity(y_test, cvec_lr_preds), \n",
    "                          metrics.specificity(y_test, cvec_svc_preds),\n",
    "                          metrics.specificity(y_test, cvec_rf_preds), \n",
    "                          metrics.specificity(y_test, cvec_xgbc_preds)]\n",
    "\n",
    "cvec_sensitivity       = [recall_score(y_test, cvec_lr_preds), \n",
    "                          recall_score(y_test, cvec_svc_preds),\n",
    "                          recall_score(y_test, cvec_rf_preds), \n",
    "                          recall_score(y_test, cvec_xgbc_preds)]\n",
    "\n",
    "cvec_rocauc_score      = [roc_auc_score(y_test, cvec_lr_preds),\n",
    "                          roc_auc_score(y_test, cvec_svc_preds),\n",
    "                          roc_auc_score(y_test, cvec_rf_preds),\n",
    "                          roc_auc_score(y_test, cvec_xgbc_preds)]\n",
    "\n",
    "cvec_matthews_corrcoef = [matthews_corrcoef(y_test, cvec_lr_preds),\n",
    "                         matthews_corrcoef(y_test, cvec_svc_preds),\n",
    "                         matthews_corrcoef(y_test, cvec_rf_preds),\n",
    "                         matthews_corrcoef(y_test, cvec_xgbc_preds)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:846: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  mcc = cov_ytyp / np.sqrt(cov_ytyt * cov_ypyp)\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# TFIDF vectorizer metrics\n",
    "\n",
    "tvec_accuracy          = [accuracy_score(y_test, tvec_lr_preds), \n",
    "                          accuracy_score(y_test, tvec_svc_preds),\n",
    "                          accuracy_score(y_test, tvec_rf_preds), \n",
    "                          accuracy_score(y_test, tvec_xgbc_preds)]\n",
    "\n",
    "tvec_specificity       = [metrics.specificity(y_test, tvec_lr_preds), \n",
    "                          metrics.specificity(y_test, tvec_svc_preds),\n",
    "                          metrics.specificity(y_test, tvec_rf_preds), \n",
    "                          metrics.specificity(y_test, tvec_xgbc_preds)]\n",
    "\n",
    "tvec_sensitivity       = [recall_score(y_test, tvec_lr_preds), \n",
    "                          recall_score(y_test, tvec_svc_preds),\n",
    "                          recall_score(y_test, tvec_rf_preds), \n",
    "                          recall_score(y_test, tvec_xgbc_preds)]\n",
    "\n",
    "tvec_rocauc_score      = [roc_auc_score(y_test, tvec_lr_preds),\n",
    "                          roc_auc_score(y_test, tvec_svc_preds),\n",
    "                          roc_auc_score(y_test, tvec_rf_preds),\n",
    "                          roc_auc_score(y_test, tvec_xgbc_preds)]\n",
    "\n",
    "tvec_matthews_corrcoef = [matthews_corrcoef(y_test, tvec_lr_preds),\n",
    "                         matthews_corrcoef(y_test, tvec_svc_preds),\n",
    "                         matthews_corrcoef(y_test, tvec_rf_preds),\n",
    "                         matthews_corrcoef(y_test, tvec_xgbc_preds)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Converting the lists into dataframes\n",
    "\n",
    "# A dataframe for the CVEC scores\n",
    "\n",
    "cvec_scores = pd.DataFrame(data    = [cvec_accuracy, cvec_specificity, \n",
    "                                      cvec_sensitivity, cvec_rocauc_score, \n",
    "                                      cvec_matthews_corrcoef],\n",
    "                           columns = [\"Log. Reg.\", \"SVC\", \"Random Forest\", \"XGBoost\"],\n",
    "                           index   = [\"Accuracy\", \"Specificity\", \n",
    "                                      \"Sensitivity\", \"AUROC Score\", \n",
    "                                      \"Matthews Corr. Coef.\"])\n",
    "\n",
    "# A dataframe for the TVEC scores\n",
    "\n",
    "tvec_scores = pd.DataFrame(data    = [tvec_accuracy, tvec_specificity, \n",
    "                                      tvec_sensitivity, tvec_rocauc_score,\n",
    "                                      tvec_matthews_corrcoef],\n",
    "                           columns = [\"Log. Reg.\", \"SVC\", \"Random Forest\", \"XGBoost\"],\n",
    "                           index   = [\"Accuracy\", \"Specificity\", \n",
    "                                      \"Sensitivity\", \"ROC-AUC Score\",\n",
    "                                      \"Matthews Corr. Coef.\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table style=\"display:inline\" border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Log. Reg.</th>\n",
       "      <th>SVC</th>\n",
       "      <th>Random Forest</th>\n",
       "      <th>XGBoost</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Accuracy</th>\n",
       "      <td>0.827338</td>\n",
       "      <td>0.827338</td>\n",
       "      <td>0.78777</td>\n",
       "      <td>0.823741</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Specificity</th>\n",
       "      <td>0.593220</td>\n",
       "      <td>0.745763</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.186441</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Sensitivity</th>\n",
       "      <td>0.890411</td>\n",
       "      <td>0.849315</td>\n",
       "      <td>1.00000</td>\n",
       "      <td>0.995434</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>AUROC Score</th>\n",
       "      <td>0.741816</td>\n",
       "      <td>0.797539</td>\n",
       "      <td>0.50000</td>\n",
       "      <td>0.590937</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Matthews Corr. Coef.</th>\n",
       "      <td>0.483631</td>\n",
       "      <td>0.543724</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.365922</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table style=\"display:inline\"><table style=\"display:inline\" border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Log. Reg.</th>\n",
       "      <th>SVC</th>\n",
       "      <th>Random Forest</th>\n",
       "      <th>XGBoost</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Accuracy</th>\n",
       "      <td>0.798561</td>\n",
       "      <td>0.830935</td>\n",
       "      <td>0.78777</td>\n",
       "      <td>0.827338</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Specificity</th>\n",
       "      <td>0.050847</td>\n",
       "      <td>0.220339</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.610169</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Sensitivity</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.995434</td>\n",
       "      <td>1.00000</td>\n",
       "      <td>0.885845</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ROC-AUC Score</th>\n",
       "      <td>0.525424</td>\n",
       "      <td>0.607886</td>\n",
       "      <td>0.50000</td>\n",
       "      <td>0.748007</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Matthews Corr. Coef.</th>\n",
       "      <td>0.201229</td>\n",
       "      <td>0.403440</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.490058</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table style=\"display:inline\">"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Displaying the two dataframes side by side\n",
    "\n",
    "display_side_by_side(cvec_scores,\n",
    "                     tvec_scores)\n",
    "\n",
    "# The first table is the CVEC scores\n",
    "# The second table is the TVEC scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# For cvec models\n",
    "\n",
    "cvec_predictions = pd.DataFrame([np.array(X_test),np.array(y_test), cvec_lr_preds, cvec_svc_preds, \n",
    "                                 cvec_rf_preds, cvec_xgbc_preds],\n",
    "                                index = [\"body\",\"Actual\",\"LgR.\", \"SVC\", \"RFC\", \"XGBC\"]).T\n",
    "\n",
    "# For tvec models\n",
    "\n",
    "tvec_predictions = pd.DataFrame([np.array(X_test),np.array(y_test), tvec_lr_preds, tvec_svc_preds, \n",
    "                                 tvec_rf_preds, tvec_xgbc_preds],\n",
    "                              index = [\"body\",\"Actual\",\"LgR.\", \"SVC\", \"RFC\", \"XGBC\"]).T\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Saving the dataframes as csvs\n",
    "\n",
    "cvec_predictions.to_csv(\"./Reddit Data/All/cvec_model_predictions_Test3.csv\")\n",
    "tvec_predictions.to_csv(\"./Reddit Data/All/tvec_model_predctions_Test3.csv\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Use Prediction Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "test_data= pd.read_csv('./Reddit Data/All/Reddit Eczema_All_20201201_Pred.csv', encoding=\"iso-8859-1\" )\n",
    "\n",
    "test_data = cleaning_data(test_data)\n",
    "\n",
    "test_data.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def predict(dataframe):\n",
    "\n",
    "    pred_text= dataframe[\"lemmatized_text\"]\n",
    "   \n",
    "    # For cvec models\n",
    "    cvec_lr_preds = cvec_lr_gs.predict(pred_text) \n",
    "    cvec_svc_preds = cvec_svc_gs.predict(pred_text) \n",
    "    cvec_rf_preds = cvec_rf_gs.predict(pred_text) \n",
    "    cvec_xgbc_preds = cvec_xgbc_gs.predict(pred_text) \n",
    "    \n",
    "    cvec_predictions = pd.DataFrame([np.array(pred_text),cvec_lr_preds, cvec_svc_preds, \n",
    "                                 cvec_rf_preds, cvec_xgbc_preds],\n",
    "                                index = [\"body\",\"LgR.\", \"SVC\", \"RFC\", \"XGBC\"]).T\n",
    "    \n",
    "    # For tvec models\n",
    "    tvec_lr_preds = tvec_lr_gs.predict(pred_text) \n",
    "    tvec_svc_preds = tvec_svc_gs.predict(pred_text) \n",
    "    tvec_rf_preds = tvec_rf_gs.predict(pred_text) \n",
    "    tvec_xgbc_preds = tvec_xgbc_gs.predict(pred_text) \n",
    "    \n",
    "    \n",
    "    tvec_predictions = pd.DataFrame([np.array(pred_text),tvec_lr_preds, tvec_svc_preds, \n",
    "                                 tvec_rf_preds, tvec_xgbc_preds],\n",
    "                                index = [\"body\",\"LgR.\", \"SVC\", \"RFC\", \"XGBC\"]).T\n",
    "    \n",
    "    # Saving the dataframes as csvs\n",
    "\n",
    "    cvec_predictions.to_csv(\"./Reddit Data/All/cvec_model_predictions_Pred5.csv\")\n",
    "    tvec_predictions.to_csv(\"./Reddit Data/All/tvec_model_predctions_Pred5.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "predict(test_data)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "REF: https://www.kdnuggets.com/2019/09/reddit-post-classification.html"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
